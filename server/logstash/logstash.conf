input {
    kafka {
        bootstrap_servers => "kafka-1:29092,kafka-2:29093"
        topics => ["logs"]
    }
}

filter {
    json {
        source => "value"
    }

    date {
        match => ["timestamp", "ISO8601"]
        target => "timestamp"
    }
}

output {
    # Elasticsearch output configuration
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "logs-index"
        workers => 1
    }

    # PostgreSQL output configuration
    # jdbc {
    #     jdbc_driver_library => "/path/to/postgresql-<version>.jar"
    #     jdbc_driver_class => "org.postgresql.Driver"
    #     jdbc_connection_string => 'jdbc:postgresql://postgres:5432/postgres'
    #     jdbc_user => "postgres"
    #     jdbc_password => "password"
    #     statement => "INSERT INTO logs (level, message, resourceId, timestamp, traceId, spanId, commit, parentResourceId) VALUES (?, ?, ?, ?, ?, ?, ?, ?)"
    #     parameters => ["[level]", "[message]", "[resourceId]", "[@timestamp]", "[traceId]", "[spanId]", "[commit]", "[metadata][parentResourceId]"]
    #     # Adjust the parameters array according to your JSON structure
    # }
}
